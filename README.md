<p align="center">
  <a href="https://medium.com/@renan_gs/usando-web-scraping-para-coletar-sequÃªncias-de-dna-f7e96150d092">
    <img width="600" src="https://i.imgur.com/6zM7JBq.png">
  </a>
</p>
<p align="center">
  <img  src="https://img.shields.io/github/license/renan-almeidaa/moveit" alt="License">

  <img src="https://img.shields.io/github/forks/renan-almeidaa/moveit" alt="Forks">     

  <img src="https://img.shields.io/github/stars/renan-almeidaa/moveit" alt="Stars">
</p>

## ðŸ’» Sobre o projeto

  Estava desenvolvendo meu TCC e precisava fazer uma mineraÃ§Ã£o em sequÃªncias de inserÃ§Ã£o em DNAs utilizando o algoritmo de ECLAT para o reconhecimento de padrÃµes frequentes. PorÃ©m, eu sÃ³ possuia 16 amostras que foram coletadas manualmente por meio do site tncentral, sendo uma quantidade pequena para realizar a mineraÃ§Ã£o. 
  
  Pesquisando um pouco, descobri uma base de dados disponilizada no github (fonte: https://github.com/thanhleviet/ISfinder-sequences ). Nele contÃ©m um arquivo csv que possui mais de 6000 sequÃªncias de DNA contendo informaÃ§Ãµes como nome, famÃ­lia, grupo, entre outros. No arquivo tambÃ©m Ã© disponibilizado o link que leva para o site do isfinder onde Ã© possÃ­vel ter acesso Ã¡ sequÃªncia.
  
  
  Dessa forma, foi possÃ­vel realizar a extraÃ§Ã£o de 307 sequÃªncias de DNA e pÃ¡ginas HTML de forma automatizadad com Web Scrapping.
  
## ðŸš€ Tecnologias

This project was developed using the following technologies:

- [Beautiful Soup](https://pypi.org/project/beautifulsoup4/)
- [Requests](https://pypi.org/project/requests/)
- [Pandas](https://pandas.pydata.org)
- [Jupyter Notebook](https://jupyter.org)

## ðŸ“Ž Mais informaÃ§Ãµes

- Para mais detalhes sobre esse projeto, acesse o meu artigo no medium -> [bit.ly/3GqGvM5](http://bit.ly/3GqGvM5)

- Para mais detalhes sobre a mineraÃ§Ã£o de dados aplicada nessa base de dados para reconhecimento de padrÃµes frequentes em sequÃªncias de inserÃ§Ã£o da famÃ­lia IS4 com o algoritmo de ECLAT e k-mers -> [bit.ly/3zFmDkI  ](https://bit.ly/3zFmDkI)
